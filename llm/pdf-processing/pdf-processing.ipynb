{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datachain and LLMs - Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing PDF documents with DataChain and Unstructured.io\n",
    "\n",
    "Most organizations keep a large source of information in the form of various internal documents, call transcripts and other unstructured data. These data contain a lot of useful insights about customers, employees or the inner workings of the company. However, they remain largely untapped by data teams due to the difficulty of dealing with large quantities of data in unstructured formats.\n",
    "\n",
    "Today, we will see how you can process a collection of documents in less than 60 lines of code and turn them into vector embeddings which are much easier to work with and useful downstream (e.g. as ML features or for RAG applications). This approach is also scalable and you will benefit from easy versioning of the final datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach and tools\n",
    "\n",
    "We will work with a publicly available MSFT azure container which contains a collection of Neurips conference papers (representing our internal company documents).\n",
    "\n",
    "For data processing we will use the  [unstructured](https://github.com/Unstructured-IO/unstructured) Python library which contains a lot of useful functionality for unstructured data processing.\n",
    "\n",
    "With unstructured we will:\n",
    "* Easily process each document\n",
    "* Partition and clean it\n",
    "* Create vector embeddings from the partitions\n",
    "\n",
    "We will also use [DataChain](https://github.com/iterative/datachain), which is an open-source Python data-frame library which helps ML and AI engineers to build a metadata layer on top of unstructured files. That way, we do not have to copy the original files anywhere or load them all to memory, significantly scaling up the volume of data we can process.\n",
    "\n",
    "With [DataChain](https://github.com/iterative/datachain), we will:\n",
    "* Easily search and filter our data container to only load the documents we need\n",
    "* Scale up the document processing with unstructured.io to the level of our entire document collection\n",
    "* Save the results as versioned datasets in tabular format, ready for processing downstream\n",
    "\n",
    "Both libraries can be easily installed with pip.\n",
    "\n",
    "```\n",
    "pip install unstructured datachain\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full working code\n",
    "\n",
    "Here you can have a look at the full code used in our example which you can run (and we will upack in a second) This code will load our document collection with DataChain and create a DataChain UDF (user-defined function) `process_pdf` which will load, partition and clean the text and create vector embeddings using `unstructured`. It then saves (and automatically versions) the resulting dataset containing the embeddings, cleaned human-readable text and a reference key for all of the original documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections.abc import Iterator\n",
    "\n",
    "from datachain.lib.dc import DataChain, C\n",
    "from datachain.lib.file import File\n",
    "from datachain.lib.data_model import DataModel\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "from unstructured.cleaners.core import clean\n",
    "from unstructured.cleaners.core import replace_unicode_quotes\n",
    "from unstructured.cleaners.core import group_broken_paragraphs\n",
    "\n",
    "from unstructured.embed.huggingface import HuggingFaceEmbeddingConfig, HuggingFaceEmbeddingEncoder\n",
    "\n",
    "# Define the output as a DataModel class\n",
    "class Chunk(DataModel):\n",
    "    key: str\n",
    "    text: str\n",
    "    embeddings: List[float]\n",
    "\n",
    "# Define embedding encoder\n",
    "\n",
    "embedding_encoder = HuggingFaceEmbeddingEncoder(\n",
    "     config=HuggingFaceEmbeddingConfig()\n",
    ")\n",
    "\n",
    "# Use signatures to define UDF input/output (these can be pydantic model or regular Python types)\n",
    "def process_pdf(file: File) -> Iterator[Chunk]:\n",
    "    # Ingest the file\n",
    "    with file.open() as f:\n",
    "        chunks = partition_pdf(file=f, chunking_strategy=\"by_title\")\n",
    "\n",
    "    # Clean the chunks and add new columns\n",
    "    for chunk in chunks:\n",
    "        chunk.apply(lambda text: clean(text, bullets=True, extra_whitespace=True, trailing_punctuation=True))\n",
    "        chunk.apply(replace_unicode_quotes)\n",
    "        chunk.apply(group_broken_paragraphs)\n",
    "\n",
    "    # create embeddings\n",
    "    chunks_embedded = embedding_encoder.embed_documents(chunks)\n",
    "\n",
    "    # Add new rows to DataChain\n",
    "    for chunk in chunks_embedded:\n",
    "        yield Chunk(\n",
    "            key=file.path,\n",
    "            text=chunk.text,\n",
    "            embeddings_new=chunk.embeddings,\n",
    "        )\n",
    "\n",
    "dc = (\n",
    "    DataChain.from_storage(\"gs://datachain-demo/neurips\")\n",
    "    .filter(C.file.path.glob(\"*.pdf\"))\n",
    "    .gen(document=process_pdf)\n",
    ")\n",
    "\n",
    "dc.save(\"embedded-documents\")\n",
    "\n",
    "DataChain.from_dataset(\"embeddings\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and saving the DataChain\n",
    "\n",
    "The following few lines of code are all that we need to load and select the right data in from our storage and to process them with `unstructured`.\n",
    "\n",
    "```python\n",
    "dc = (\n",
    "    DataChain.from_storage(\"gs://datachain-demo/neurips\")\n",
    "    .filter(C.file.path.glob(\"*.pdf\"))\n",
    "    .gen(document=process_pdf)\n",
    ")\n",
    "```\n",
    "\n",
    "Let's unpack:\n",
    "\n",
    "The `from_storage` and `filter` methods allow us to ingest the data from a bucket/storage container. Since DataChain uses lazy evaluation, no other files than those specified by the `filter` will be loaded, speeding up the process considerably.\n",
    "This will create a DataChain metadata table containing all the information needed to process our PDF files without actually having to copy the files themselves or load them all to memory. Since DataChain operates on a metadata level, it can scale up billions of files without us having to worry about memory overflows.\n",
    "\n",
    "The `gen` method allows us to modify the datachain table and create new rows (potentially more than one per original table row) using datachain UDF functions. Here, the UDF `process_pdf` does all the individual PDF processing with `unstructured`.\n",
    "\n",
    "Finally, we save the table as a dataset by calling \n",
    "\n",
    "```python\n",
    "dc.save(\"embedded-documents\")\n",
    "```\n",
    "\n",
    "This will persist the table and version it (each time we call this command a new version is created automatically). We can then load and display it by the following command, optionally specifying the dataset version\n",
    "\n",
    "```python\n",
    "DataChain.from_dataset(\"embeddings\", version=1).show()\n",
    "```\n",
    "\n",
    "All that's missing is the DataChain UDF definition, so let's see how we do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the UDF\n",
    "\n",
    "The `process_pdf` UDF will take the original datachain table and produce an output with `embeddings` of processed document chunks. We also want to keep the original `text` of each processed document chunk and a `key` by which we can link each chunk back to the original full document.\n",
    "\n",
    "We first specify what we actually want to receive on the output of our UDF by defining the `DataModel`-based `Chunk` class and defining the output column types:\n",
    "\n",
    "```python\n",
    "# Define the output as a DataModel class\n",
    "class Chunk(DataModel):\n",
    "    key: str\n",
    "    text: str\n",
    "    embeddings: List[float]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define the `process_pdf` function itself. We use Python signatures to specify the input and output. Here, `File` is a class used by Datachain to refer to the original file - a PDF document in our case. On the output we use `Iterator` since our function will produce multiple chunks (and so multiple rows in our DataChain table) per original file.\n",
    "\n",
    "```python\n",
    "def process_pdf(file: File) -> Iterator[Chunk]:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the function definition as well as the definition of `embedding_encoder` specifies how `unstructured` is used to process each individual PDF file. For more detail on how this is done you can check out the tutorial in the [unstructured documentation](https://docs.unstructured.io/open-source/core-functionality/overview).\n",
    "\n",
    "Finally, we want the UDF to produce new rows in our DataChain table and so we have it return the Chunk objects we specified above. Here, we use `yield` instead of `return` as each PDF file produces several Chunk objects.\n",
    "\n",
    "```python\n",
    "    # Add new rows to DataChain\n",
    "    for chunk in chunks_embedded:\n",
    "        yield Chunk(\n",
    "            key=file.name.removesuffix(\"-Paper.pdf\"),\n",
    "            text=chunk.text,\n",
    "            embeddings_new=chunk.embeddings,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have processed our collection of documents to create a dataset of embeddings. We could now proceed \n",
    "\n",
    "Stay tuned for Part II, where we will explore a use-case where we will use a similar approach to process call centre recordings to create and process transcripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
